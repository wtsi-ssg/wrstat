/*******************************************************************************
 * Copyright (c) 2022 Genome Research Ltd.
 *
 * Author: Sendu Bala <sb10@sanger.ac.uk>
 *
 * Permission is hereby granted, free of charge, to any person obtaining
 * a copy of this software and associated documentation files (the
 * "Software"), to deal in the Software without restriction, including
 * without limitation the rights to use, copy, modify, merge, publish,
 * distribute, sublicense, and/or sell copies of the Software, and to
 * permit persons to whom the Software is furnished to do so, subject to
 * the following conditions:
 *
 * The above copyright notice and this permission notice shall be included
 * in all copies or substantial portions of the Software.
 *
 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
 * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
 * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.
 * IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY
 * CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT,
 * TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE
 * SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
 ******************************************************************************/

// package pathsize is for storaing path->size data in a database and querying
// it.

package pathsize

import (
	"bytes"
	"encoding/binary"
	"io"
	"os"
	"syscall"

	bolt "go.etcd.io/bbolt"
)

type Error string

func (e Error) Error() string { return string(e) }

const (
	bucket         = "pathsize"
	dbOpenMode     = 0600
	binaryBytes    = 8
	ErrDBExists    = Error("database already exists")
	ErrDBNotExists = Error("database doesn't exist")
	ErrDirNotFound = Error("directory not found")
)

// a psdb holds our database and the path it should be written to or read from.
type psdb struct {
	path       string
	pathToSize *bolt.DB
}

// newPSDB creates a new psdb that knows where its database file is located or
// should be created.
func newPSDB(path string) *psdb {
	return &psdb{
		path: path,
	}
}

// Create creates a new database file. Returns an error if it already exist.
func (p *psdb) Create() error {
	if p.pathExists() {
		return ErrDBExists
	}

	var err error

	p.pathToSize, err = openBoltWritable(p.path, bucket)

	return err
}

// pathExists tells you if the our database path already exists.
func (p *psdb) pathExists() bool {
	info, err := os.Stat(p.path)
	if err == nil && info.Size() != 0 {
		return true
	}

	return false
}

// openBoltWritable creates a new database at the given path with the given
// bucket inside.
func openBoltWritable(path, bucket string) (*bolt.DB, error) {
	db, err := bolt.Open(path, dbOpenMode, &bolt.Options{
		NoFreelistSync: true,
		NoGrowSync:     true,
		FreelistType:   bolt.FreelistMapType,
	})
	if err != nil {
		return nil, err
	}

	err = db.Update(func(tx *bolt.Tx) error {
		_, errc := tx.CreateBucketIfNotExists([]byte(bucket))

		return errc
	})

	return db, err
}

// Open opens our constituent database read-only.
func (p *psdb) Open() error {
	var err error

	p.pathToSize, err = openBoltReadOnly(p.path)

	return err
}

// openBoltReadOnly opens a bolt database at the given path in read-only mode.
func openBoltReadOnly(path string) (*bolt.DB, error) {
	return bolt.Open(path, dbOpenMode, &bolt.Options{
		ReadOnly:  true,
		MmapFlags: syscall.MAP_POPULATE,
	})
}

// Close closes our constituent database.
func (p *psdb) Close() error {
	return p.pathToSize.Close()
}

// PathSize holds path and size information.
type PathSize struct {
	Path string
	Size uint64
}

// sizeAsBytes converts our size to a byte slice.
func (p *PathSize) sizeAsBytes() []byte {
	b := make([]byte, binaryBytes)
	binary.LittleEndian.PutUint64(b, p.Size)

	return b
}

// DB is used to create and query a database made from a size file, which is the
// path,size output produced by the stat packages' SizeOperation() function.
type DB struct {
	paths      []string
	write      *psdb
	readers    []*psdb
	batchSize  int
	writeBatch []*PathSize
	writeI     int
	writeErr   error
}

// NewDB returns a *DB that can be used to create or query a pathsize database.
// Provide the path to the database file. In the case of only reading databases
// with Open(), you can supply multiple databases to query all of them
// simultaneously.
func NewDB(paths ...string) *DB {
	return &DB{paths: paths}
}

// Store will read the given size file data (as generated by
// stat.SizeOperation()) and store it in a database file that offer fast lookup
// of size by file path.
//
// The path for the database file you provided to NewDB() (only the first will
// be used) must not already have content in it to create a new database. You
// can't add to an existing database. If you create multiple sets of data to
// store, instead Store them to separate database files, and then load all them
// together during Open().
//
// batchSize is how many files worth of information are written to the database
// in one go. More is faster, but uses more memory. 10,000 might be a good
// number to try.
func (d *DB) Store(data io.Reader, batchSize int) error {
	d.batchSize = batchSize

	err := d.createDB()
	if err != nil {
		return err
	}

	defer func() {
		errc := d.write.Close()
		if err == nil {
			err = errc
		}
	}()

	if err = d.storeData(data); err != nil {
		return err
	}

	if d.writeBatch[0] != nil {
		d.storeBatch()
	}

	err = d.writeErr

	return err
}

// createDB creates a new database set, but only if it doesn't already exist.
func (d *DB) createDB() error {
	d.write = newPSDB(d.paths[0])

	return d.write.Create()
}

// storeData parses the data and stores it in our database file. Only call this
// after calling createDB(), and only call it once.
func (d *DB) storeData(data io.Reader) error {
	d.resetBatch()

	return parsePathSizeLines(data, d.parserCB)
}

// resetBatch prepares us to receive a new batch of lines from the parser.
func (d *DB) resetBatch() {
	d.writeBatch = make([]*PathSize, d.batchSize)
	d.writeI = 0
}

// parserCB is a pathSizeParserCallBack that is called during parsing of size
// file data. It batches up the PathSize we receive, and writes them to the
// database when a batch is full.
func (d *DB) parserCB(ps *PathSize) {
	d.writeBatch[d.writeI] = ps
	d.writeI++

	if d.writeI == d.batchSize {
		d.storeBatch()
		d.resetBatch()
	}
}

// storeBatch writes the current batch of PathSize to the database.
func (d *DB) storeBatch() {
	if d.writeErr != nil {
		return
	}

	err := d.write.pathToSize.Update(d.storePathSize)
	if err != nil {
		d.writeErr = err
	}
}

// storePathSize stores the PathSizes of the current batch in the db.
func (d *DB) storePathSize(tx *bolt.Tx) error {
	b := tx.Bucket([]byte(bucket))

	for _, ps := range d.writeBatch {
		if ps == nil {
			return nil
		}

		if err := b.Put([]byte(ps.Path), ps.sizeAsBytes()); err != nil {
			return err
		}
	}

	return nil
}

// Open opens the database(s) for reading. You need to call this before using
// the query methods. You should call Close() after you've finished.
func (d *DB) Open() error {
	readers := make([]*psdb, len(d.paths))

	for i, path := range d.paths {
		readDB := newPSDB(path)

		if !readDB.pathExists() {
			return ErrDBNotExists
		}

		err := readDB.Open()
		if err != nil {
			return err
		}

		readers[i] = readDB
	}

	d.readers = readers

	return nil
}

// Close closes the database(s) after reading. You should call this once
// you've finished reading, but it's not necessary; errors are ignored.
func (d *DB) Close() {
	if d.readers == nil {
		return
	}

	for _, db := range d.readers {
		db.Close()
	}
}

// SizeOf returns the size of the given path. If path not in the database,
// the size will be 0 and bool will be false.
func (d *DB) SizeOf(path string) (uint64, bool) {
	var found bool

	var size uint64

	bpath := []byte(path)

	for _, db := range d.readers {
		db.pathToSize.View(func(tx *bolt.Tx) error { //nolint:errcheck
			b := tx.Bucket([]byte(bucket))

			v := b.Get(bpath)
			if v == nil {
				return nil
			}

			size = bytesToSize(v)
			found = true

			return nil
		})

		if found {
			break
		}
	}

	return size, found
}

// bytesToSize converts our size from bytes back to a uint64.
func bytesToSize(v []byte) uint64 {
	return binary.LittleEndian.Uint64(v)
}

// GetChildren returns a PathSize for every file in the database that is nested
// within the given dir.
func (d *DB) GetChildren(dir string) []*PathSize {
	var pss []*PathSize

	bdir := []byte(dir)

	for _, db := range d.readers {
		db.pathToSize.View(func(tx *bolt.Tx) error { //nolint:errcheck
			c := tx.Bucket([]byte(bucket)).Cursor()

			for k, v := c.Seek(bdir); k != nil && bytes.HasPrefix(k, bdir); k, v = c.Next() {
				pss = append(pss, &PathSize{Path: string(k), Size: bytesToSize(v)})
			}

			return nil
		})

		if len(pss) > 0 {
			break
		}
	}

	return pss
}
